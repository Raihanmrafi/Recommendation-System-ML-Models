{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cA_VW-ZV4Kcr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Dense, concatenate, Input, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI8Kq0l74d77",
        "outputId": "755f6fa2-c619-4db2-854d-504baf574bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['id', 'name', 'description', 'price_range', 'min_order', 'order_req',\n",
            "       'supply_ability', 'history_view_product', 'user_id', 'order_click',\n",
            "       'image'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('product.csv', delimiter=';')\n",
        "\n",
        "# Lihat nama kolom yang ada di DataFrame\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rElr9QCZ4ged",
        "outputId": "fc281580-04e1-47a8-b976-b1f4b3255a87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-d82ca3148113>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[['order_click', 'history_view_product', 'min_order']] = scaler.fit_transform(data[['order_click', 'history_view_product', 'min_order']])\n"
          ]
        }
      ],
      "source": [
        "# Select relevant columns for recommendation system\n",
        "data = data[['id', 'name', 'order_click', 'history_view_product', 'min_order']]\n",
        "\n",
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "data[['order_click', 'history_view_product', 'min_order']] = scaler.fit_transform(data[['order_click', 'history_view_product', 'min_order']])\n",
        "\n",
        "# Convert data to numpy array\n",
        "product_features = data[['order_click', 'history_view_product', 'min_order']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3dbT2mA5dvu",
        "outputId": "67910e94-53d7-42aa-b534-ba6b79b15b27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test = train_test_split(product_features, test_size=0.2, random_state=42)\n",
        "# Build Simple AutoEncoder Model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(product_features.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(product_features.shape[1])  # Output layer, tanpa aktivasi karena ini adalah masalah rekonstruksi\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M7-r1n2x5h_-",
        "outputId": "35f420fe-3151-4104-ce62-f2e1e2ba7c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 1s 51ms/step - loss: 0.9302 - val_loss: 0.9764\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8142 - val_loss: 0.8706\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7075 - val_loss: 0.7621\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5993 - val_loss: 0.6480\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4862 - val_loss: 0.5234\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3751 - val_loss: 0.3929\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2674 - val_loss: 0.2656\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1741 - val_loss: 0.1565\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1012 - val_loss: 0.0761\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0488 - val_loss: 0.0315\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0274 - val_loss: 0.0191\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0199\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0171 - val_loss: 0.0194\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0159\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0105\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0091\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0083\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0079\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0043 - val_loss: 0.0063\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0039 - val_loss: 0.0055\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0050\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 0.0048\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0045\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0031 - val_loss: 0.0042\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0036\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0034\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0034\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0031\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0029\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0016\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.8947e-04 - val_loss: 0.0017\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 9.6321e-04 - val_loss: 0.0015\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 9.3679e-04 - val_loss: 0.0015\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9.2090e-04 - val_loss: 0.0015\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.0435e-04 - val_loss: 0.0014\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 8.8029e-04 - val_loss: 0.0015\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8.4237e-04 - val_loss: 0.0014\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8.3236e-04 - val_loss: 0.0014\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8.2528e-04 - val_loss: 0.0013\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 8.0273e-04 - val_loss: 0.0013\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.6710e-04 - val_loss: 0.0013\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.2632e-04 - val_loss: 0.0013\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 7.1911e-04 - val_loss: 0.0012\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 6.7929e-04 - val_loss: 0.0013\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.6133e-04 - val_loss: 0.0011\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.5539e-04 - val_loss: 0.0012\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 6.4933e-04 - val_loss: 0.0011\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.2265e-04 - val_loss: 0.0011\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.0801e-04 - val_loss: 0.0011\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.9732e-04 - val_loss: 0.0011\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.9708e-04 - val_loss: 0.0011\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 5.7234e-04 - val_loss: 0.0011\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.4108e-04 - val_loss: 0.0011\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.3917e-04 - val_loss: 9.8568e-04\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.3040e-04 - val_loss: 0.0010\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.0891e-04 - val_loss: 9.6378e-04\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.1207e-04 - val_loss: 0.0011\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.0046e-04 - val_loss: 9.5162e-04\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9053e-04 - val_loss: 9.6035e-04\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 4.7091e-04 - val_loss: 9.7443e-04\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 4.6715e-04 - val_loss: 9.4232e-04\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 4.5868e-04 - val_loss: 8.9771e-04\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.4520e-04 - val_loss: 9.5514e-04\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 4.3635e-04 - val_loss: 9.0067e-04\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 4.3055e-04 - val_loss: 8.5948e-04\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 4.1646e-04 - val_loss: 9.0514e-04\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.1181e-04 - val_loss: 8.9202e-04\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.0706e-04 - val_loss: 8.9241e-04\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.9353e-04 - val_loss: 8.5533e-04\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.8717e-04 - val_loss: 8.6546e-04\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.7262e-04 - val_loss: 8.4104e-04\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.7382e-04 - val_loss: 8.2993e-04\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.6515e-04 - val_loss: 8.2543e-04\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.5780e-04 - val_loss: 8.2762e-04\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4812e-04 - val_loss: 8.0262e-04\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4815e-04 - val_loss: 8.3471e-04\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.3572e-04 - val_loss: 7.8866e-04\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.4197e-04 - val_loss: 8.0168e-04\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2905e-04 - val_loss: 7.8433e-04\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.1752e-04 - val_loss: 7.7343e-04\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.1332e-04 - val_loss: 7.6424e-04\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.1405e-04 - val_loss: 7.6075e-04\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.1870e-04 - val_loss: 7.6180e-04\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.2419e-04 - val_loss: 7.7503e-04\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.0786e-04 - val_loss: 7.3538e-04\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.0158e-04 - val_loss: 7.6442e-04\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.8556e-04 - val_loss: 7.2958e-04\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.7801e-04 - val_loss: 7.2164e-04\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8386e-04 - val_loss: 7.2144e-04\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7802e-04 - val_loss: 7.3628e-04\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.6925e-04 - val_loss: 6.9843e-04\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.6334e-04 - val_loss: 7.1000e-04\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.6525e-04 - val_loss: 7.2699e-04\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.6469e-04 - val_loss: 6.6856e-04\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.5044e-04 - val_loss: 7.0390e-04\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4874e-04 - val_loss: 6.6899e-04\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.4592e-04 - val_loss: 6.8988e-04\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.4278e-04 - val_loss: 6.5121e-04\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.4036e-04 - val_loss: 6.9879e-04\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.3643e-04 - val_loss: 6.6533e-04\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.3249e-04 - val_loss: 6.3468e-04\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.3184e-04 - val_loss: 6.6990e-04\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2718e-04 - val_loss: 6.5904e-04\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.2327e-04 - val_loss: 6.5456e-04\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1833e-04 - val_loss: 6.6013e-04\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1831e-04 - val_loss: 6.1988e-04\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1456e-04 - val_loss: 6.4019e-04\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.1402e-04 - val_loss: 6.5207e-04\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.1574e-04 - val_loss: 6.3684e-04\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.1523e-04 - val_loss: 6.7834e-04\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1340e-04 - val_loss: 6.2478e-04\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9944e-04 - val_loss: 6.3094e-04\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.9608e-04 - val_loss: 6.0661e-04\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9912e-04 - val_loss: 6.4914e-04\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9030e-04 - val_loss: 6.3662e-04\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.0351e-04 - val_loss: 6.5308e-04\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9599e-04 - val_loss: 6.0969e-04\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9431e-04 - val_loss: 6.2131e-04\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8798e-04 - val_loss: 6.0122e-04\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9104e-04 - val_loss: 6.3957e-04\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8367e-04 - val_loss: 5.8813e-04\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7566e-04 - val_loss: 6.0723e-04\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7748e-04 - val_loss: 6.2387e-04\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.7446e-04 - val_loss: 5.8024e-04\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7678e-04 - val_loss: 6.3642e-04\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7807e-04 - val_loss: 6.0377e-04\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7155e-04 - val_loss: 6.0560e-04\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6928e-04 - val_loss: 6.0062e-04\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6340e-04 - val_loss: 6.0623e-04\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6614e-04 - val_loss: 5.9251e-04\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7250e-04 - val_loss: 5.7989e-04\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.7692e-04 - val_loss: 6.0217e-04\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6494e-04 - val_loss: 5.6898e-04\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5845e-04 - val_loss: 5.6358e-04\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5770e-04 - val_loss: 5.9739e-04\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5570e-04 - val_loss: 5.6994e-04\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6225e-04 - val_loss: 5.6376e-04\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5011e-04 - val_loss: 6.0212e-04\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4841e-04 - val_loss: 5.7386e-04\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.4678e-04 - val_loss: 5.7170e-04\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4255e-04 - val_loss: 5.7486e-04\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3936e-04 - val_loss: 5.4594e-04\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3986e-04 - val_loss: 5.8817e-04\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3680e-04 - val_loss: 5.6361e-04\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3686e-04 - val_loss: 5.6389e-04\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3535e-04 - val_loss: 5.6829e-04\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3127e-04 - val_loss: 5.6894e-04\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3270e-04 - val_loss: 5.3875e-04\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3134e-04 - val_loss: 5.7547e-04\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3263e-04 - val_loss: 5.5087e-04\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3355e-04 - val_loss: 5.6987e-04\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3786e-04 - val_loss: 5.6694e-04\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4227e-04 - val_loss: 5.4627e-04\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3185e-04 - val_loss: 5.4983e-04\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3290e-04 - val_loss: 5.9640e-04\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2814e-04 - val_loss: 5.3000e-04\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2681e-04 - val_loss: 5.9072e-04\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2364e-04 - val_loss: 5.2920e-04\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2144e-04 - val_loss: 5.3819e-04\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2039e-04 - val_loss: 5.4248e-04\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2081e-04 - val_loss: 5.6180e-04\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2015e-04 - val_loss: 5.2356e-04\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1350e-04 - val_loss: 5.4872e-04\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1291e-04 - val_loss: 5.5409e-04\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1569e-04 - val_loss: 5.2846e-04\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1205e-04 - val_loss: 5.2081e-04\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1403e-04 - val_loss: 5.5413e-04\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1804e-04 - val_loss: 5.2556e-04\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0983e-04 - val_loss: 5.5802e-04\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1062e-04 - val_loss: 5.2762e-04\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1150e-04 - val_loss: 5.2642e-04\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0567e-04 - val_loss: 5.3180e-04\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0693e-04 - val_loss: 5.2564e-04\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0625e-04 - val_loss: 5.4319e-04\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0908e-04 - val_loss: 5.3947e-04\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0841e-04 - val_loss: 5.0925e-04\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0539e-04 - val_loss: 5.4566e-04\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.9314e-05 - val_loss: 5.0192e-04\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9.8542e-05 - val_loss: 5.3396e-04\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9.9681e-05 - val_loss: 5.1045e-04\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0249e-04 - val_loss: 5.5520e-04\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.0892e-04 - val_loss: 4.9717e-04\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.0074e-04 - val_loss: 5.3172e-04\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9.5850e-05 - val_loss: 4.9979e-04\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 9.7464e-05 - val_loss: 5.1838e-04\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 9.4031e-05 - val_loss: 5.0304e-04\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 9.3429e-05 - val_loss: 5.1592e-04\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 9.2275e-05 - val_loss: 5.0312e-04\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 9.0147e-05 - val_loss: 5.2131e-04\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.6066e-05 - val_loss: 5.1967e-04\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.7088e-05 - val_loss: 4.9223e-04\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.4369e-05 - val_loss: 5.0457e-04\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.9225e-05 - val_loss: 5.2186e-04\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9.4181e-05 - val_loss: 5.1167e-04\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.0022e-05 - val_loss: 4.9008e-04\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.7238e-05 - val_loss: 5.0880e-04\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 8.6357e-05 - val_loss: 4.9354e-04\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 8.7107e-05 - val_loss: 4.8940e-04\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 8.3194e-05 - val_loss: 5.1002e-04\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8.8382e-05 - val_loss: 4.9898e-04\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 7.9926e-05 - val_loss: 4.8205e-04\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.3115e-05 - val_loss: 5.1851e-04\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 8.0928e-05 - val_loss: 4.8153e-04\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 8.4801e-05 - val_loss: 4.9338e-04\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 8.2540e-05 - val_loss: 4.8988e-04\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.8201e-05 - val_loss: 4.7107e-04\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.7112e-05 - val_loss: 5.2869e-04\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.2918e-05 - val_loss: 4.8144e-04\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 8.0763e-05 - val_loss: 4.8357e-04\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 7.6870e-05 - val_loss: 4.7737e-04\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 7.7058e-05 - val_loss: 4.7120e-04\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 7.5790e-05 - val_loss: 4.9978e-04\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 7.7674e-05 - val_loss: 5.0791e-04\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 7.6324e-05 - val_loss: 4.5067e-04\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.4573e-05 - val_loss: 5.0339e-04\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.5965e-05 - val_loss: 4.9033e-04\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 7.6318e-05 - val_loss: 5.0335e-04\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 7.0665e-05 - val_loss: 4.6144e-04\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.1654e-05 - val_loss: 4.7878e-04\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.0817e-05 - val_loss: 4.6932e-04\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.5468e-05 - val_loss: 4.7510e-04\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 7.2976e-05 - val_loss: 4.7784e-04\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 7.6551e-05 - val_loss: 4.8557e-04\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.9728e-05 - val_loss: 4.6866e-04\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.8872e-05 - val_loss: 4.9294e-04\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.9677e-05 - val_loss: 4.5673e-04\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.8008e-05 - val_loss: 4.7098e-04\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.8565e-05 - val_loss: 4.7062e-04\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.5450e-05 - val_loss: 4.7000e-04\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.7204e-05 - val_loss: 4.7828e-04\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.4645e-05 - val_loss: 4.5381e-04\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.2373e-05 - val_loss: 4.7027e-04\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.1841e-05 - val_loss: 4.6289e-04\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.4958e-05 - val_loss: 4.6412e-04\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5696e-05 - val_loss: 4.6792e-04\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5484e-05 - val_loss: 4.8873e-04\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.7622e-05 - val_loss: 4.5274e-04\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 7.1681e-05 - val_loss: 4.6667e-04\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.7963e-05 - val_loss: 4.7736e-04\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.2745e-05 - val_loss: 4.5410e-04\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7219e-05 - val_loss: 4.5978e-04\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.5201e-05 - val_loss: 4.5372e-04\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.0734e-05 - val_loss: 4.6136e-04\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.7652e-05 - val_loss: 4.3546e-04\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.9925e-05 - val_loss: 4.8026e-04\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.1859e-05 - val_loss: 4.6100e-04\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.5558e-05 - val_loss: 4.6474e-04\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.1023e-05 - val_loss: 4.5072e-04\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.2318e-05 - val_loss: 4.3729e-04\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.8990e-05 - val_loss: 4.6055e-04\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7565e-05 - val_loss: 4.4298e-04\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5296e-05 - val_loss: 4.5796e-04\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 6.5809e-05 - val_loss: 4.7222e-04\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5309e-05 - val_loss: 4.7847e-04\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5147e-05 - val_loss: 4.5924e-04\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.6379e-05 - val_loss: 4.4045e-04\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.8548e-05 - val_loss: 4.4368e-04\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.7391e-05 - val_loss: 4.6103e-04\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.1561e-05 - val_loss: 4.3716e-04\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.3406e-05 - val_loss: 4.5159e-04\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.3223e-05 - val_loss: 4.6378e-04\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.7625e-05 - val_loss: 4.5157e-04\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 5.4678e-05 - val_loss: 4.7765e-04\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.4487e-05 - val_loss: 4.2371e-04\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.3587e-05 - val_loss: 4.6235e-04\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.3120e-05 - val_loss: 4.3657e-04\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.4153e-05 - val_loss: 4.4358e-04\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.1363e-05 - val_loss: 4.6148e-04\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.0335e-05 - val_loss: 4.2804e-04\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 5.1351e-05 - val_loss: 4.4273e-04\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.1753e-05 - val_loss: 4.5284e-04\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.1944e-05 - val_loss: 4.3224e-04\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.1494e-05 - val_loss: 4.2992e-04\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.0706e-05 - val_loss: 4.4776e-04\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.1078e-05 - val_loss: 4.2418e-04\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.1962e-05 - val_loss: 4.3737e-04\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.8769e-05 - val_loss: 4.5134e-04\n"
          ]
        }
      ],
      "source": [
        "# Train the model with hyperparameter\n",
        "history = model.fit(X_train, X_train, epochs=300, batch_size=32, shuffle=True, validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "W6__5Cm85wNb",
        "outputId": "d9b88cc8-130f-4cc8-8dae-2d0f2d37410d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 10ms/step - loss: 4.5134e-04\n",
            "Mean Squared Error (MSE) pada data testing: 0.0004513440653681755\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# MSE Count on Data Testing \n",
        "mse = model.evaluate(X_test, X_test)\n",
        "print(\"Mean Squared Error (MSE) pada data testing:\", mse)\n",
        "\n",
        "# Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8t02yKF76OT",
        "outputId": "64f085fb-043b-4325-e15f-d69643017465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "['Wood Flooring', 'Wood Furniture', 'Cacao Nacional Grade A', 'Coffee Gayo Grade 5', 'Wood Plywood']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Get latent representation of products\n",
        "product_embeddings = encoder_model.predict(product_features)\n",
        "\n",
        "# Function to get product recommendations\n",
        "def get_recommendations(product_id, embeddings, product_data, top_k=5):\n",
        "    # Calculate cosine similarity with all products\n",
        "    similarities = cosine_similarity([embeddings[product_id]], embeddings)[0]\n",
        "    # Get indices of top_k most similar products\n",
        "    similar_indices = similarities.argsort()[-top_k-1:-1][::-1]\n",
        "    # Get names of recommended products\n",
        "    recommended_product_names = product_data.iloc[similar_indices]['name'].tolist()\n",
        "    return recommended_product_names\n",
        "\n",
        "# Get 5 recommendations for product with ID 0\n",
        "recommended_products = get_recommendations(0, product_embeddings, data, top_k=5)\n",
        "print(recommended_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voSVDemeT19y",
        "outputId": "7a97f138-9514-43ec-f875-e80832c5ad57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "autoencoder.save('Model1_CBF.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
